\vspace{-2.5cm}
\chapter*{\zihao{2}\heiti{摘~~~~要}}
%\vskip 1cm
%\vspace{-1cm}

随着人工智能的快速发展与移动设备的普及，需要多个参与方协作的应用场景不断涌现，分布式数据处理和分布式机器学习的作用日益凸显。比如分散在多个银行的金融数据、不同医院里的医疗记录、大平台下的每个用户的行为记录，以及智能电表、传感器或移动设备等产生的数据都需要分布式处理与挖掘。数据孤岛是分布式数据处理和分布式机器学习面临的重要挑战之一，作为解决数据孤岛的解决方案，联邦学习是一种很有前景的分布式计算框架，可以在多个分散的边缘设备上本地训练模型，而无需将其数据传输到服务器。随着公民隐私意识的提高和相法律的完善，联邦学习中的隐私安全问题也日益受到人们的关注，且最新的研究工作表明已经能通过对模型的梯度参数进行攻击，还原用户的隐私数据，即仅通过保持数据的局部性来保护隐私是不够的，并且隐私保护技术在保护隐私的同时，还会牺牲模型精度。为此，本文使用差分隐私技术来保护联邦学习中用户的隐私，并针对分布式场景，分析模型训练过程中针对梯度下降算法的自适应干扰机制，实现提高模型精度的目的，并提出安全shuffle框架，防止恶意服务器的攻击。本文主要工作包括如下几个方面：

本文主要的工作和贡献如下：
\begin{enumerate}
	\item 为解决现有隐私算法通常需要牺牲模型精度来提高模型隐私性，从而使得模型可用性降低的挑战，我们对联邦学习场景下的本地差分模型进行了三方面的优化：第一，针对模型训练中的梯度加噪，提出了一个自适应加噪机制；第二，相对于传统的隐私预算平均分配，提出了一个更好的隐私预算分配策略；第三，根据所加的噪声量的大小分配权重，减小整体的噪声影响。
	\item 在上述算法的基础上，进一步提出安全聚合模型，从而按需分配隐私模型，降低全局模型的噪声影响。此外，我们还分析了在差分隐私机制下联邦学习算法的收敛性，并根据训练中的两个误差项分别提了改进方法，即裁剪值学习方法和改进的组合方法。
	\item 我们基于三个基准测试集评估了框架和算法的可行性和有效性，并且在实验中与其他方案对比，展示了模型精度的提升和隐私成本的节省。
\end{enumerate}
\hspace{-0.5cm}
\sihao{\heiti{关键词：}} \xiaosi{联邦学习，隐私保护，本地差分隐私，安全聚合}
