\vspace{-2.5cm}
\chapter*{\zihao{2}\heiti{摘~~~~要}}
%\vskip 1cm
%\vspace{-1cm}

随着数据孤岛的出现和隐私意识的普及，联邦学习作为一种新兴的数据共享和交换模型，基本框架包含多个本地设备和一个中央服务器，所有训练数据保存在本地设备，所有设备共同协作训练一个全局模型。联邦学习的一个突出优点是它可以在服务器和客户端之间无需任何个人数据交换的情况下进行本地训练，在金融、医疗、教育等诸多领域得到广泛应用。但是，联邦学习也存在各种安全和隐私问题。近年来，大量的研究结果表明，联邦学习机制仍然存在安全问题，在训练过程中，本地设备与中央服务器之间的通信信道和传递的模型参数都有可能成为第三方窃取敏感信息的途径，联邦学习的框架仍然存在本地训练数据泄漏等隐私威胁。作为一种新的神经网络训练模型，攻击者可以从共享梯度中跟踪和获取参与者的本地数据隐私，造成数据泄漏的问题，联邦学习仍然面临各种安全和隐私威胁。针对联邦学习中用户本地训练数据的攻击方式包括投毒攻击、模型重建攻击、模型反演攻击、成员推理攻击等。

随着针对联邦学习框架的攻击模型增多，研究人员开始关注训练联邦学习模型时存在的隐私安全问题。针对联邦学习中的隐私保护的技术主要分为两类，一类是基于密码学技术，比如安全多方计算、同态加密等；另一类是基于系统安全技术，包括差分隐私、ESA框架、混洗框架等。基于安全多方计算的联邦学习隐私保护技术主要是在联邦学习中应用不经意传输、混淆电路、秘密共享等技术达到隐私保护的目的；基于同台加密的联邦学习隐私保护技术主要是通过加法同态、乘法同态或者全同态加密技术对用户上传的参数进行加密，以防止中央服务器或者恶意第三方服务器的攻击。虽然这两种密码学技术对数据的隐私保护效果很好，但应用于实际的联邦学习环境中，会出现模型难以收敛、计算成本过高、通信效率降低等问题；而差分隐私等系统安全技术却在模型精度、通信效率上能达到更好的效果。因此，本文主要是基于系统安全技术对联邦学习中的隐私保护问题进行研究。

当前在联邦学习模型中应用差分隐私的主流方案是在本地训练随机梯度下降过程中，在梯度上添加噪声。Song等人\upcite{ref47}提出了一个$\left(\epsilon_{c}+\epsilon_{d}\right)$-差分隐私版本的随机梯度下降算，在本地模型的每一次迭代过程中，对梯度添加高斯噪声，并通过差分隐私的组合性和隐私放大效果，得到完全隐私损失的上界。差分隐私随机梯度下降 (DP-SGD) 严重降低了训练模型的效用，在数据集上训练和验证的损失率大大增加。因此本文针对模型效用和数据隐私保护的双重目标，设计、实现并评估了一个实用的联邦学习系统，该系统在保护数据隐私的前提下尽可能的维持了模型的精度和通信效率。本文主要的工作和贡献如下：

\begin{enumerate}
\item [(1)] 在联邦学习差分隐私的场景下，本文设计了一种新型的、基于本地差分隐私的权重分配自适应干扰算法和梯度自适应裁剪算法。首先，我们考虑到不同的深度神经网络（DNN）层的模型权重可能会有很大的变化，提出了一种权重分配自适应干扰算法：在客户端本地训练的神经网络模型中，通过分析前向传播算法，计算每个属性类对于模型输出的贡献比。我们设计了一个自适应噪声添加的方案，根据梯度的贡献率注入不同隐私预算的噪声。我们还进一步证明了所提出的自适应范围设置如何能够极大地提高聚合模型的准确性，特别是在更深的模型中。

\item [(2)]在传统的差分隐私随机梯度下降算法中，通常采用固定的裁剪阈值对梯度进行裁剪以限制函数的敏感度并添加与敏感度界限成比例的高斯噪声，然而固定的梯度裁剪可能添加额外的噪声。本文设计了一种自适应调整剪裁阈值的方案，通过计算梯度更新的方差和偏差，逐元素地对梯度进行裁剪，与之前的方案相比，通过使用梯度的坐标自适应剪裁实现了相同的隐私保证，而增加的噪声要少得多。之后我们利用"Moments Account"机制分析加噪累积产生的隐私预算，并证明了算法满足$\left(\epsilon_{c}+\epsilon_{l}\right)$-差分隐私。与传统的注入噪声的方法相比，我们在相同的隐私保护程度下大大减少了噪声对模型输出结果的影响，提高了模型的准确性。

\item [(3)] 由于本地差分隐私并不能有效防御针对联邦学习的生成对抗网络攻击，并且在通信轮数较大的联邦学习模型中，本地自适应差分隐私的强组合性质和会导致总体隐私预算过高。本文提出了一种新的安全聚合机制，在本地客户端和中心服务器之间新增安全混洗器，在用户将参数上传到云服务器之前，先对参数进行拆分混洗，模型参数的更新被匿名的发送到混洗器，通过对模型参数的拆分和混洗实现客户端匿名，并减轻由联邦学习模型的高数据维度和大量查询迭代引起的隐私预算爆炸问题。

\item [(4)] 为了验证本文的方案在实际生产环境中的可行性，本文模拟了联邦学习环境，分别在MNIST、CIFAR-10、FMNIST三种数据集上进行实验，首先通过控制变量法分析各个参数对于模型精度的影响和隐私保护的效用，并与前人的差分隐私方案和安全混洗方案进行对比，通过实验结果证明了自适应本地差分隐私方案和安全混洗框架的结合，在较低的隐私预算下还能使联邦学习模型维持较高的精度。
\end{enumerate}
\hspace{-0.5cm}
\sihao{\heiti{关键词：}} \xiaosi{联邦学习，隐私保护，差分隐私，安全混洗}
