\vspace{-2.5cm}
\chapter*{\zihao{2}\heiti{摘~~~~要}}
%\vskip 1cm
%\vspace{-1cm}

随着机器学习成为一种实践和商品，提供了大量基于云的服务和框架来帮助客户开发和部署机器学习应用程序。虽然在云中外包模型训练和服务任务很普遍，但保护训练数据集中敏感样本的隐私并防止信息泄露给不受信任的第三方也很重要。过去的工作表明，恶意机器学习服务提供商或最终用户可以轻松地从模型参数甚至模型输出中提取有关训练样本的关键信息。

在大数据时代，数据隐私已成为最重要的问题之一。 迄今为止，存在大量安全策略和加密算法，试图确保敏感数据不会受到损害。此外，其中大部分安全策略都假设只有拥有密钥的人才能访问机密数据。然而，随着机器学习的广泛使用，特别是集中式机器学习，为了训练有用的模型，数据应该被收集并转移到一个中心点。 因此，对于那些隐私敏感的数据，难免会面临数据泄露的风险。 因此，如何在不泄漏数据的情况下对私有数据集进行机器学习是共享智能的关键问题。基于隐私保护，具有多方隐私保护的机器学习可以帮助各方用户在保证自身数据安全的前提下，共同学习彼此的数据。 其中，联邦学习是一种典型的有助于解决多方计算下的隐私问题的学习方法。

随着数据孤岛的出现和隐私意识的普及，联邦学习作为一种新兴的数据共享和交换模型，可以在保护数据隐私和安全的前提下实现多方协作，因为分布在多个设备上的数据无法发送当地。为实现各方利益，在金融、医疗、教育等诸多领域得到广泛应用。但是，联邦学习也存在各种安全和隐私问题。本文从联邦学习的概述出发，详细描述了威胁模型和存在的安全问题，包括模型重建攻击、中毒攻击、推理攻击等，然后对联邦学习隐私保护安全技术进行了一定的分析。与安全多方计算和同态加密相比，差分隐私在效率方面非常出色。 

在本文中，我们开发了一种基于自适应差分隐私混洗的联邦学习算法。 该模型是在多方隐私保护下通过梯度学习联合训练的。具体来说，该模型在每次迭代中通过梯度下降进行优化，并且可以通过传递梯度来从其他用户的数据中学习。

本文主要的工作和贡献如下：
\begin{enumerate}
\item [(1)] 在联邦学习差分隐私的场景下，本文提出了一种新型的、基于本地差分隐私的权重分配自适应干扰算法。在客户端本地训练的神经网络模型中，通过分析前向传播算法，计算每个属性类对于模型输出的贡献比，然后，我们设计了一个自适应噪声添加的方案，根据贡献率注入不同隐私预算的噪声。之后我们设计了动量组合机制分析加噪累积产生的隐私预算，并证明了算法满足$\left(\epsilon_{c}+\epsilon_{l}\right)$-差分隐私。与传统的注入噪声的方法相比，我们在相同的隐私保护程度下大大减少了噪声对模型输出结果的影响，提高了模型的准确性。
\item [(2)] 考虑到联邦学习中参数聚合器的攻击和针对参数传播信道的攻击，本文提出了一种新的安全聚合机制，在本地客户端和中心服务器之间新增混洗器，在用户将参数上传到云服务器之前，先对参数进行混洗，模型参数的更新被匿名的发送到混洗器，通过对模型参数的拆分和混洗实现客户端匿名，并且证明了安全混洗模型的可行性。
\item [(3)] 本文在三种数据集上进行实验，并与前人的方案进行对比，证明了自适应本地差分隐私方案和安全混洗框架的结合，在较低的隐私预算下还能使联邦学习模型维持较高的精度。
\end{enumerate}
\hspace{-0.5cm}
\sihao{\heiti{关键词：}} \xiaosi{联邦学习，隐私保护，差分隐私，安全混洗}
