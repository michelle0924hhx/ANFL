\vspace{-2.5cm}
\chapter*{\zihao{2}\heiti{摘~~~~要}}
%\vskip 1cm
%\vspace{-1cm}

随着人工智能的快速发展与移动设备的普及，需要多个参与方协作的应用场景不断涌现，分布式数据处理和分布式机器学习的作用日益凸显。比如分散在多个银行的金融数据、不同医院里的医疗记录、大平台下的每个用户的行为记录，以及智能电表、传感器或移动设备等产生的数据都需要分布式处理与挖掘。数据孤岛是分布式数据处理和分布式机器学习面临的重要挑战之一，作为解决数据孤岛的解决方案，联邦学习是一种很有前景的分布式计算框架，可以在多个分散的边缘设备上本地训练模型，而无需将其数据传输到服务器。随着公民隐私意识的提高和相法律的完善，联邦学习中的隐私安全问题也日益受到人们的关注，且最新的研究工作表明已经能通过对模型的梯度参数进行攻击，还原用户的隐私数据，即仅通过保持数据的局部性来保护隐私是不够的，并且隐私保护技术在保护隐私的同时，还会牺牲模型精度。为此，本文使用差分隐私技术来保护联邦学习中用户的隐私，并针对分布式场景，分析模型训练过程中针对梯度下降算法的自适应干扰机制，实现提高模型精度的目的，并提出安全混洗模型，防止恶意服务器的攻击。本文主要工作包括如下几个方面：

本文主要的工作和贡献如下：
\begin{enumerate}
\item [(1)] 在联邦学习差分隐私的场景下，本文提出了一种新型的、基于本地差分隐私的权重分配自适应干扰算法。在客户端本地训练的神经网络模型中，通过分析前向传播算法，计算每个属性类对于模型输出的贡献比，然后，我们设计了一个自适应噪声添加的方案，根据贡献率注入不同隐私预算的噪声。之后我们设计了解析高斯机制分析加噪累积的隐私预算，并证明了算法满足$\left(\epsilon_{c}+\epsilon_{l}\right)$-差分隐私。与传统的注入噪声的方法相比，我们在相同的隐私保护程度下最大限度地提高了模型的准确性，减少噪声对模型输出结果的影响，提高模型精度。
\item [(2)] 考虑到联邦学习中参数聚合器的攻击和针对参数传播信道的攻击，本文提出了一种新的安全聚合机制，在本地客户端和中心服务器之间新增混洗器，在用户将参数上传到云服务器之前，先对参数进行混洗，模型参数的更新被匿名的发送到混洗器，通过对模型参数的拆分和混洗实现客户端匿名，并且证明了安全混洗模型的可行性。
\item [(3)] 本文在三种数据集上进行实验，并与前人的方案进行对比，证明了自适应本地差分隐私方案和安全混洗框架的结合，在较低的隐私预算下还能使联邦学习模型维持较高的精度。
\end{enumerate}
\hspace{-0.5cm}
\sihao{\heiti{关键词：}} \xiaosi{联邦学习，隐私保护，本地差分隐私，安全混洗}
