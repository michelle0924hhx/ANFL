\chapter{总结与展望}
\label{ch6}
\section{总结}
随着深度学习的兴起，出现了越来越多新的模型和算法，能够更有效的解决各类问题。基于人工智能的产品也在各个领域迎来了一波新的发展热潮，给人民的生活带来了巨大的便利。然而用户在享受深度学习模型带来便利的同时，必须共享自己的数据，随着隐私泄露事件越来越多，数据的安全和隐私问题也逐步引起了人们的关注。 

与此同时，各类智能设备也在不断发展，用户产生的数据也越来越多，智能设备的算力不断增强。用户不愿意向商业公司或商业机构提供个人隐私数据。分布式联邦学习系统解决分布式终端用户在本地更新模型的问题，联邦学习的目标是保障大数据共享信息时的数据安全、保护本地数据和个人隐私，在多计算节点之间高效的训练机器学习模型。 

分布式联邦学习系统得到了广泛的研究和应用，成为传统集中式机器学习方法的一种改进方法。它不是将数据上传到中心服务器进行集中训练，而是参与者在本地进行模型训练并与参数服务器共享模型更新。参数服务器对来自多个参与者的权重进行聚合，并组合创建一个改进的全局模型，这有助于保障用户的数据隐私和降低通信成本。 

本文主要研究针对分布式联邦学习系统的隐私安全问题。通过研究分布式联邦深度学习的系统漏洞，提出了一套针对分布式数据的攻击模型，同时研究分布式联邦系统中针对攻击的隐私安全方案对策。本文的主要工作和贡献如下：
\begin{enumerate}
\item [(1)] 本文提出了一个满足本地差分隐私的分类变换扰动机制．该机制将数值型数据的扰动与分类型数据的扰动进行结合，提高了均值估计的准确性．同时，将该机制用于梯度下降中的每次迭代的梯度扰动，保护了训练过程中用户隐私的同时得到了 1 个较为准确的模型．而且，本文也从本地差分隐私定义的角度，理论证明了提出的方法满足$\mathcal{E}$-本地差分隐私．最后通过多组真实数据集以及合成数据集验证了分类变换扰动机制的性能，证明了其在相同条件下要优于现有的同类方法。

\item [(2)] 本文提出了SA安全混洗框架，混洗差分隐私摒弃了中心化差分隐私下对可信第三方的依赖，即无需任何可信第三方。对用户的原始数据进行统一的扰动处理，提高了隐私性；弥补了中心化差分隐私与本地化差分隐私在可用性上约O( n) 的间隙[9-30]，在差分隐私的保证下实现了数据隐私度与可用性之间的更好平衡。
\end{enumerate}

综上所述，本文的研究充分证明了所提出框架的有效性，可以极大的联邦学习模型的隐私性和可用性，从而进一步推进了联邦学习在安全领域的应用和发展。

\section{展望}
在可预见的未来，大规模、大数据、分布式的深度学习将得到快速发展。5G、边缘计算、物联网等技术也将迅速普及。人类将彻底步入人工智能时代。在此我将对我未来的研究做出几点展望：
\begin{enumerate}
\item [(1)] 本文提出的基于解析高斯机制与函数机制的差分隐私深度学习算法是一种基础算法，它可以令学习模型在训练过程中总体隐私不累加。因此后续可以研究其在大型数据集与复杂模型结构中的表现。 
\item [(2)] 现实中，分布式协作学习可能由极多的参与者组成，如百万部手机等。同时分布式协作学习中的每个设备可能计算、通信和存储能力等都有很大不同。因此有关实际应用中的通信、异构问题等也需要进行大量的研究。 
\item[(3)] 分布式协作学习需要一个公平的平台和激励机制，可以在实际应用中明显体现出效果提升，并能够在永久数据记录机制（如区块链等）中留下记录。这样才能促进分布式协作学习的商业化与大规模应用。
\end{enumerate}

