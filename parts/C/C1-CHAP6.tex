\chapter{总结与展望}
\label{ch6}
\section{论文总结}
随着深度学习的兴起，出现了越来越多新的模型和算法，能够更有效的解决各类问题。基于人工智能的产品也在各个领域迎来了一波新的发展热潮，给人民的生活带来了巨大的便利。然而用户在享受深度学习模型带来便利的同时，必须共享自己的数据，随着隐私泄露事件越来越多，数据的安全和隐私问题也逐步引起了人们的关注。 

与此同时，各类智能设备也在不断发展，用户产生的数据也越来越多，智能设备的算力不断增强。用户不愿意向商业公司或商业机构提供个人隐私数据。分布式联邦学习系统解决分布式终端用户在本地更新模型的问题，联邦学习的目标是保障大数据共享信息时的数据安全、保护本地数据和个人隐私，在多计算节点之间高效的训练机器学习模型。 

分布式联邦学习系统得到了广泛的研究和应用，成为传统集中式机器学习方法的一种改进方法。它不是将数据上传到中心服务器进行集中训练，而是参与者在本地进行模型训练并与参数服务器共享模型更新。参数服务器对来自多个参与者的权重进行聚合，并组合创建一个改进的全局模型，这有助于保障用户的数据隐私和降低通信成本。 虽然联邦学习解决了传统集中式深度学习所面临的大规模数据收集等问题，节省了传输数据所占用的通信资源。但是，联邦学习中的共享参数以及传输数据的无线链路仍然可能泄露数据隐私。各类攻击模型阻碍了联邦学习技术的发展，也会极大地威胁到人们的隐私敏感信息。

本文主要研究针对分布式联邦学习系统的隐私安全问题。通过研究神经网络的前向传播算法和差分隐私的相关性质，提出了一套分布式联邦系统中针对梯度和通信信道攻击的隐私安全方案对策。本文的主要工作和贡献如下：
\begin{enumerate}
\item [(1)] 基于本地差分隐私的自适应干扰算法：在客户端本地训练的神经网络模型中，通过分析前向传播算法，计算每个属性类对于模型输出的贡献比，然后，我们开发了一个自适应噪声添加的方案，根据贡献率注入不同隐私预算的噪声。与传统的注入噪声的方法相比，我们在相同的隐私保护程度下最大限度地提高了模型的准确性，减少噪声对模型输出结果的影响，提高模型精度。而且，本文也从本地差分隐私定义的角度，理论证明了提出的方法满足$\mathcal{E}$-本地差分隐私．最后通过多组真实数据集以及合成数据集验证了本地自适应扰动机制的性能，证明了其在相同条件下要优于现有的同类方法。
\item [(2)] 本文提出了SA安全混洗框架，混洗器对客户端上传的梯度进行采样后，然后拆分混洗，再将混洗模型和自适应本地差分隐私保护方法结合在分布式系统中，提高系统学习效果，在差分隐私的保证下实现了数据隐私度与模型可用性之间的更好平衡。
\end{enumerate}

综上所述，本文的研究充分证明了所提出框架的有效性，可以极大的联邦学习模型的隐私性和可用性，从而进一步推进了联邦学习在安全领域的应用和发展。

\section{论文展望}
在可预见的未来，大规模、大数据、分布式的深度学习将得到快速发展。物联网、5G、边缘计算等技术也将迅速普及。人类将彻底步入人工智能时代。在此我将对我未来的研究做出几点展望：
\begin{enumerate}
	\item [(1)] 本文提出的基于本地自适应混洗差分隐私深度学习算法是一种基础算法，在模型学习的过程中，它的总体隐私预算并不会随着通信回合的增加而大幅上升。因此后续可以研究其在大型数据集与复杂模型结构中的表现。
	\item [(2)] 差分隐私对于数据的保护是基于数学证明的，但是缺乏一定的可解释性，如果能够在差分隐私保护深度学习模型上建立更加有效的隐私风险评估和隐私成本评估指标，那么将来应该能更好的应用差分隐私，推动深度学习机制下的差分隐私保护的研究发展。
	\item [(3)] 现实生活中，联邦学习的参与方数量可能有百万、千万的级别。当客户端的量级大大增加时，由于本地设备在通信、计算和存储等各个方面的能力大有不同，因此之后关于实际应用中的通信成本、设备异构等方面也需要大量的研究。
\end{enumerate}

