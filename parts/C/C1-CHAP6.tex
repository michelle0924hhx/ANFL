\chapter{总结与展望}
\label{ch6}
\section{论文总结}
随着大数据、机器学习、深度学习的快速发展，人工智能在各个领域都得到了广泛的应用，比如，自动驾驶、医疗诊断、图像识别等。人工智能算法基于大数据实现模型的泛化和学习，而训练数据可能包含了大量的用户敏感信息，例如个人医疗记录、员工信息、财务数据等。我们的搜索查询、浏览历史、购买交易、我们观看的视频以及我们的观影偏好都有可能被收集在移动设备和计算机中，这有可能导致用户的隐私泄露。随着隐私泄漏的事件越来越多，数据安全和隐私问题引起了人们的关注。我国在2018年我国正式颁布了《信息安全技术和个人信息安全规范》以规范个人信息收集和存储的安全性。

人工智能的服务性能在很大程度上受到训练数据质量的影响。在大多数行业中，数据是以孤立的岛屿形式存在的。具体而言，不同的机构拥有不同的用户行为数据和特征数据，由于商业竞争模式和法律法规监管，企业之间无法共享数据以构建一个高质量的模型。在破解数据孤岛问题和实现数据隐私保护的双重需求下，联邦学习作为一种新型的深度学习范式应运而生。在联邦学习框架中，有许多参与方，在无需传递和共享本地的数据资源的情况下训练一个共同的、强大的深度学习模型，即数据依然保留在用户侧，而模型是共享的。

与传统的集中式深度学习相比，联邦学习在一定程度上缓解了数据孤岛和隐私泄露的问题。然而，许多研究表明，攻击者仍然可以通过梯度损害用户的隐私。由于联邦学习仍然需要一个能够回答查询函数的聚合模型，这意味着聚合后的梯度仍然包含了本地数据的信息。由于联邦学习的框架并没有对参与方的资质进行校验、没有对模型的访问权加以约束。一些恶意的参与方通过向中央服务器提供虚假的参数影响联邦学习模型的质量，甚至导致整体模型不可用；还有一些攻击者从通信信道中获取共享梯度，根据梯度反演得到用户数据集相关的信息。差分隐私是当前保护联邦学习隐私安全的前沿技术，其通过严格的统计框架提供隐私保证和隐私成本计算，使得加躁后的梯度不能泄露关于实体数据的敏感信息，与安全多方计算和同态加密等密码学技术相比，差分隐私保护联邦学习的方案在通信性能和计算性能方面与明文计算相差不大。

为了在差分隐私框架下保护联邦学习的隐私性，必须在本地训练过程或全局聚合过程中向模型参数注入噪声。然而当前的差分隐私保护联邦深度学习的方案通常面临模型可用性和数据隐私性的博弈。差分隐私的应用可能导致模型的准确率下降，而且随着迭代次数的增多，高维加躁梯度的聚合会导致梯度中所包含的有效信息被噪声所淹没，影响全局模型的收敛性。如何在保护本地数据隐私的同时降低模型的精度损失，以及在千万量级的联邦学习通信回合下，避免噪声量的成倍增加导致模型的通信性能和可用性大幅下降是当前亟需研究的问题。

本文的研究内容主要针对联邦深度学习系统的成员推理攻击和生成对抗网络攻击设计隐私保护方案，基于隐私性、模型精度、通信性能的三重指标，设计了本地自适应差分隐私算法和top-K安全混洗算法，主要的工作和贡献包含以下四个方面：
\begin{enumerate}
\item [(1)] 在差分隐私联邦学习的场景下，本文设计了一种新型的、基于本地差分隐私的自适应梯度加躁算法。由于不同的神经网络层的神经元对于模型输出的影响不同，本文设计了一种基于神经元的贡献率添加自适应噪声的算法：在客户端本地训练的神经网络模型中，通过运行逐层关联传播算法，计算每个神经元对于模型输出的贡献率。在随机梯度下降过程中，根据贡献率分配动态的隐私预算，在梯度上注入高斯噪声。在设置相同的隐私预算下，相比于DP-SGD算法，我们的方案在相同的隐私保护程度下大大减少了噪声对模型输出结果的影响，与固定的梯度加躁和裁剪的方案相比提高了模型的准确性和收敛速度。

\item [(2)]在传统的差分隐私随机梯度下降算法中，通常采用固定的裁剪阈值对梯度进行裁剪以限制函数的敏感度，然而固定的梯度裁剪可能添加额外的噪声。本文设计了一种自适应调整剪裁阈值的方案，通过计算梯度更新的方差和偏差，逐元素地对梯度进行裁剪，根据神经网络各层的均值和统计特征进行梯度裁剪既能限制敏感度有界，也能保留有效的梯度信息。之后我们利用“Moments Accountant”机制分析加噪累积产生的隐私预算，给出更精准的隐私界。

\item [(3)]由于本地差分隐私并不能有效防御针对联邦学习的生成对抗网络攻击，并且在通信轮数较大的联邦学习模型中，由于差分隐私的强组合性质，噪声量成倍累加，导致整体的隐私成本过高。本文设计了一种新型的联邦学习安全混洗算法，采用指数机制的打分原理挑选出绝对值排名前k位的梯度元素，添加拉普拉斯扰动，设计了满足$(\epsilon, \delta)$-差分隐私的Top-K梯度选择算法。此外，在联邦学习模型中新增安全混洗器，通过对梯度和索引所构成的矩阵进行置乱，提高了数据的随机性。在每轮通信回合，根据指数衰减机制动态调整客户端采样率，减少整体通信负荷。通过客户端的采样和梯度索引的混洗达到双重的隐私放大效应，降低系统的整体隐私损失，提高了通信性能，并证明了安全混洗框架的隐私性和全局收敛性。

\item [(4)]为了验证本文的方案在实际生产环境中的可行性，本文模拟了联邦学习环境，分别在MNIST、CIFAR-10、FMNIST等数据集上进行实验，首先通过控制变量法分析各个参数对于模型精度和通信性能的影响，并与前人的差分隐私方案和安全混洗方案进行对比，通过实验结果证明了自适应本地差分隐私算法和安全混洗算法，在保护数据隐私的前提下尽可能的减小了模型的精度损耗，降低了通信成本。最后，本文模拟了成员推理攻击和生成对抗网络攻击，评估了自适应差分隐私方案和安全混洗方案针对攻击模型的隐私保护效用。

\end{enumerate}
综上所述，本文的研究充分证明了所提出框架的有效性，可以极大的联邦学习模型的隐私性和可用性，从而进一步推进了联邦学习在安全领域的应用和发展。

\section{论文展望}
% 在可预见的未来，大规模、大数据、分布式的深度学习将得到快速发展。物联网、5G、边缘计算等技术也将迅速普及。人类将彻底步入人工智能时代。在此我将对未来的研究方向做出几点展望：
% \begin{enumerate}
% 	\item [(1)] 本文提出的基于本地自适应混洗差分隐私深度学习算法是一种基础算法，在模型学习的过程中，它的总体隐私预算会随着通信回合的增加而大幅上升，因此后续可以研究其在大型数据集与复杂模型结构中的表现。
% 	\item [(2)] 差分隐私对于数据的保护是基于数学证明的，但是缺乏一定的可解释性，如果能够在差分隐私保护联邦学习模型上建立更加有效的隐私风险评估和隐私成本评估指标，那么将来应该能更好的应用差分隐私，推动联邦学习机制下的差分隐私保护的研究发展。
% 	\item [(3)] 现实生活中，联邦学习的参与方数量可能有百万、千万的级别。当客户端的量级大大增加时，由于本地设备在通信、计算和存储等各个方面的能力大有不同，因此之后关于实际应用中的通信成本、设备异构等方面也需要大量的研究。
% \end{enumerate}

